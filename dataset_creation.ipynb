{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv.VideoCapture(0)\n",
    "if not camera.isOpened():\n",
    "    print(\"Camera not opened\")\n",
    "    exit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = [\"angry\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
    "\n",
    "for label in Labels:\n",
    "    if not os.path.exists(label):\n",
    "        os.mkdir(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 's' to start data collection for angry\n",
      "Press 's' to start data collection for happy\n",
      "Press 's' to start data collection for sad\n",
      "Press 's' to start data collection for surprise\n",
      "Press 's' to start data collection for neutral\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "for folder in Labels:\n",
    "    #using count variable to name the images in the dataset.\n",
    "    count = 0\n",
    "    #Taking input to start the capturing\n",
    "    print(\"Press 's' to start data collection for \"+folder)\n",
    "    userinput = input()\n",
    "    if userinput != 's':\n",
    "        print(\"Wrong Input..........\")\n",
    "        exit()\n",
    "    #clicking 200 images per label, you could change as you want.    \n",
    "    while count<400:\n",
    "        #read returns two values one is the exit code and other is the frame\n",
    "        status, frame = camera.read()\n",
    "        #check if we get the frame or not\n",
    "        if not status:\n",
    "            print(\"Frame is not been captured..Exiting...\")\n",
    "            break\n",
    "        #convert the image into gray format for fast caculation\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        #display window with gray image\n",
    "        cv.imshow(\"Video Window\",gray)\n",
    "\n",
    "        #using cv to detect faces in the frame and croppe it. this is what is going to be stored in the dataset\n",
    "        face_cascade = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for x,y,w,h in faces:\n",
    "            cv.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 1)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            cropped_img = cv.resize(roi_gray,(48,48))\n",
    "            cv.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv.NORM_L2, dtype=cv.CV_32F)\n",
    "            cv.imwrite(folder+'/'+ folder +str(count)+'.jpg',cropped_img)\n",
    "            count+=1\n",
    "        #display the frame with rectangle around the face\n",
    "        cv.imshow(\"Video Window\",frame)\n",
    "        count+=1\n",
    "\n",
    "        #to quite the display window press 'q'\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "\n",
    "# When everything done, release the capture\n",
    "camera.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo esto es parte de data_transformation.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Definir las emociones y sus correspondientes valores enteros\n",
    "emotion_dict = {0: \"angry\", 1: \"happy\", 2: \"sad\", 3: \"surprise\", 4: \"neutral\"}\n",
    "\n",
    "# Crear listas vacías para almacenar los datos del conjunto de datos\n",
    "emotion = []\n",
    "pixels = []\n",
    "usage = []\n",
    "\n",
    "# Iterar a través de cada carpeta de emociones\n",
    "for emotion_folder in os.listdir(\"dataset\"):\n",
    "    # Obtener el valor entero correspondiente a la emoción actual\n",
    "    emotion_label = list(emotion_dict.keys())[\n",
    "        list(emotion_dict.values()).index(emotion_folder)\n",
    "    ]\n",
    "\n",
    "    # Iterar a través de cada imagen en la carpeta actual\n",
    "    for image_filename in os.listdir(os.path.join(\"dataset\", emotion_folder)):\n",
    "        # Leer la imagen y convertirla a escala de grises\n",
    "        image_path = os.path.join(\"dataset\", emotion_folder, image_filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Aplanar la imagen en un vector de una dimensión\n",
    "        flat_image = gray_image.flatten()\n",
    "\n",
    "        # Agregar los datos al conjunto de datos\n",
    "        emotion.append(emotion_label)\n",
    "        flat_image_to_string = \" \".join(str(x) for x in list(flat_image))\n",
    "        pixels.append(flat_image_to_string)\n",
    "\n",
    "        # Establecer la etiqueta de uso del conjunto de datos (Training, PrivateTest, PublicTest)\n",
    "        rand_num = np.random.rand()\n",
    "        if rand_num < 0.5:\n",
    "            usage.append(\"Training\")\n",
    "        elif rand_num < 0.75:\n",
    "            usage.append(\"PrivateTest\")\n",
    "        else:\n",
    "            usage.append(\"PublicTest\")\n",
    "\n",
    "# Crear un dataframe de pandas para almacenar los datos del conjunto de datos\n",
    "df = pd.DataFrame({\"emotion\": emotion, \"pixels\": pixels, \"Usage\": usage})\n",
    "\n",
    "# Guardar el conjunto de datos como un archivo CSV\n",
    "df.to_csv(\"dataset.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
